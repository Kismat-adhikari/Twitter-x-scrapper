#!/usr/bin/env python3
"""
Test script to verify improved large target handling
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scraper.playwright_scraper import TwitterScraper
import time

def test_large_target():
    print("üß™ TESTING: Large target (200 tweets) handling")
    print("=" * 60)
    
    start_time = time.time()
    
    scraper = TwitterScraper()  # Auto tab count
    
    # Use a broader search to ensure content
    result = scraper.scrape(
        keyword='python',  # Broader than previous complex search
        num_tweets=200,
        job_id='test_large_target'
    )
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nüìä TEST RESULTS:")
    print(f"‚è±Ô∏è  Duration: {duration:.1f} seconds")
    print(f"üìÅ File: {result}")
    
    if result:
        # Check actual tweet count
        import csv
        try:
            with open(f'scraped_data/{result}', 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                next(reader)  # Skip header
                actual_count = sum(1 for row in reader)
            
            print(f"üéØ Target: 200 tweets")
            print(f"‚úÖ Actual: {actual_count} tweets")
            print(f"üìà Success rate: {actual_count/200*100:.1f}%")
            print(f"üöÄ Speed: {actual_count/duration:.1f} tweets/second")
            
            if actual_count >= 150:  # 75% success is good for large targets
                print(f"‚úÖ SUCCESS: Got {actual_count} tweets (good for large target)!")
                return True
            else:
                print(f"‚ö†Ô∏è  Partial success: Got {actual_count}/200 tweets")
                return False
        except Exception as e:
            print(f"‚ùå Error reading file: {e}")
            return False
    else:
        print("‚ùå FAILED: No file created")
        return False

if __name__ == "__main__":
    test_large_target()